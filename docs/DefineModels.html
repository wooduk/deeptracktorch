---

title: Implementing Neural Network Architecture for exracting particle prediction

keywords: fastai
sidebar: home_sidebar

summary: "Needs to follow this convention"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/01_DefineModels.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
    {% raw %}
        
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="https://www.osapublishing.org/optica/abstract.cfm?uri=optica-6-4-506">Helgadottir, Argun, and Volpe (2019)</a> described the convolutional neural network architecture that they created and trained. The diagram summarising the structure of this network from their paper is shown here:</p>
<p><img src="/deeptracktorch/DeepTrackArch.png" alt="Architecture Diagram"></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In summary this network takes an image 51 x 51 pixels as input and passes it through 3 convolutional layers. Effectively these redescribe the images as features. There are then two densly connected layers which finally connect to a 3 value output layers.</p>
<ul>
<li>The first convolutional layer runs 16 3 x 3 kernels over the image, producing 16 channels of size 49 x 49.</li>
<li>Each of these channels is like a map of intensity for a different feature, perhaps a top edge for example. During training the network learns the weights for these kernels. In effect it learns what features are important for it to minimise error in the output.</li>
<li>In between the red layers are max-pooling layers that downsample the channels.</li>
<li>it is typical for the list of features (i.e. number of channels) to rise as we go deeper. This is like detecting richer more complex features as we go along)</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Implementation-in-PyTorch">Implementation in PyTorch<a class="anchor-link" href="#Implementation-in-PyTorch">&#182;</a></h2><p>The original paper implements this network using the Keras a Deep Learning framework, based on TensorFlow. I have chosen to re-implement the architecture in a different framework: PyTorch to take advantage of the fastai library for efficient training.</p>
<p>I want to step through the layers of the network and understand the inputs and outputs at each stage. The final network is defined at the bottom of the notebook for the impatient.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Loading-an-image-into-a-Tensor">Loading an image into a Tensor<a class="anchor-link" href="#Loading-an-image-into-a-Tensor">&#182;</a></h3><p>For working through this example I need to load in a sample image. There is some manipulation required because we need to have the data in a Torch Tensor, ensure it is greyscale (single channel) and the correct size.</p>
<p>PyTorch comes with some helper transform functions that can be used for this task:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can use the Python Imaging library (PIL) to load in the image from a file and then apply these transforms. Also we have to make the tensor of the right rank (dimensions) to be fed into our proposed network architecture.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>

<span class="k">def</span> <span class="nf">image_loader</span><span class="p">(</span><span class="n">transforms</span><span class="p">,</span> <span class="n">image_name</span><span class="p">):</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">image_name</span><span class="p">)</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">transforms</span><span class="p">(</span><span class="n">image</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">image</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Try it out. Load an image and check the size.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_image</span><span class="o">=</span><span class="n">image_loader</span><span class="p">(</span><span class="n">data_transforms</span><span class="p">,</span> <span class="s1">&#39;0000.jpg&#39;</span><span class="p">)</span>
<span class="n">test_image</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([1, 1, 51, 51])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now you can't remember why it has to be that shape can you??</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Convolutions">Convolutions<a class="anchor-link" href="#Convolutions">&#182;</a></h3><p>I had to remind myself what happens with convolutions. Here we define a 3 x 3 kernel. The values of the weight are chosen from an example elsewhere. Convolving this kernel with an image has the effect of 'finding' diagonal edges. [src?]</p>
<p>First this is how the kernel would be defined as a Tensor.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">k</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span>
    <span class="p">[</span><span class="mf">0.</span>  <span class="p">,</span><span class="o">-</span><span class="mi">5</span><span class="o">/</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>
    <span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="o">/</span><span class="mi">3</span><span class="p">,</span><span class="o">-</span><span class="mi">5</span><span class="o">/</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">1.</span>  <span class="p">,</span><span class="mi">1</span>   <span class="p">,</span><span class="mi">1</span><span class="p">],</span>
<span class="p">])</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span><span class="o">/</span><span class="mi">6</span>
<span class="n">k</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([1, 1, 3, 3])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The extra dimensons are required because ... (1 is for the 1 channel of the input, the other is something to do with PyTorch)</p>
<p>Now we can use some of the functionality of PyTorch. <code>conv2d</code> is a function that performed the convolution of our kernel, <code>k</code>, with our <code>test_image</code>:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="n">edge</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">test_image</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span>
<span class="n">edge</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([1, 1, 49, 49])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This gives the output of 49 x 49 as expected (because of the size of our kernel), let's have a quick look at it.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">edge</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,:,:],</span><span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Greys&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.image.AxesImage at 0x12a210220&gt;</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So, to recreate the first convlutional layer of the proposed network we can create a kernel that has 16 filters of 3 x 3 and convolve that with the image.</p>
<blockquote><p><em>given that the original image is 51×51px, the first convolutional layer produces 16 feature maps of 49×49px</em></p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">k</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span>
    <span class="p">[</span><span class="mf">0.</span>  <span class="p">,</span><span class="o">-</span><span class="mi">5</span><span class="o">/</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>
    <span class="p">[</span><span class="o">-</span><span class="mi">5</span><span class="o">/</span><span class="mi">3</span><span class="p">,</span><span class="o">-</span><span class="mi">5</span><span class="o">/</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">1.</span>  <span class="p">,</span><span class="mi">1</span>   <span class="p">,</span><span class="mi">1</span><span class="p">],</span>
<span class="p">])</span><span class="o">/</span><span class="mi">6</span>

<span class="n">k16</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>

<span class="n">conv1</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="n">k16</span><span class="p">)</span>
<span class="n">conv1</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">conv1</span><span class="p">)</span>
<span class="n">conv1</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([1, 16, 49, 49])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Yes.</p>
<p>The next layer is a MaxPooling2D layer to reduce the size of each layer:</p>
<blockquote><p><em>the first max-pooling layer downsamples them to 24×24px</em></p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pool1</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">conv1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">pool1</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([1, 16, 24, 24])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The next group of layers should do this:</p>
<blockquote><p><em>the second convolutional layer produces 32 feature maps of 22 × 22 px and the second max-pooling layer downsamples them to 11 × 11 px;</em></p>
</blockquote>
<p>To start, define a kernel that can be convolved with the output of previous layers. This will be a 3 x 3 filter that works on all 16 channels that we produced last time. We want the output to be 32 filters.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># define kernel</span>
<span class="n">k32</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span><span class="mi">16</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># do convolution layer</span>
<span class="n">conv2</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">pool1</span><span class="p">,</span> <span class="n">k32</span><span class="p">)</span>
<span class="n">conv2</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">conv2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;conv2:&quot;</span><span class="p">,</span><span class="n">conv2</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># do downsample</span>
<span class="n">pool2</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">conv2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;pool2:&quot;</span><span class="p">,</span><span class="n">pool2</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>conv2: torch.Size([1, 32, 22, 22])
pool2: torch.Size([1, 32, 11, 11])
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now the final convolutional layer:</p>
<blockquote><p><em>and the third convolutional layer produces 64 feature maps of 9 × 9 px and the third max-pooling layer downsamples them to 4 × 4 px</em></p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># define kernel</span>
<span class="n">k32</span> <span class="o">=</span> <span class="n">k</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># do convolution layer</span>
<span class="n">conv3</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">pool2</span><span class="p">,</span> <span class="n">k32</span><span class="p">)</span>
<span class="n">conv3</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">conv3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;conv3:&quot;</span><span class="p">,</span><span class="n">conv2</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># do downsample</span>
<span class="n">pool3</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">max_pool2d</span><span class="p">(</span><span class="n">conv3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;pool3:&quot;</span><span class="p">,</span><span class="n">pool3</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>conv3: torch.Size([1, 32, 22, 22])
pool3: torch.Size([1, 64, 4, 4])
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To connect the 2D outut of the final convolutional layer to the next set of Dense linear layers we must first 'flatten' it.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">flat_pool3</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">pool3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;flat_pool3:&quot;</span><span class="p">,</span><span class="n">flat_pool3</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>flat_pool3: torch.Size([1024])
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Then we can add to Linear layers.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">weights1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span><span class="mi">1024</span><span class="p">)</span>
<span class="n">lin1</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">flat_pool3</span><span class="p">,</span><span class="n">weights1</span><span class="p">)</span>
<span class="n">lin1</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">lin1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;lin1:&quot;</span><span class="p">,</span><span class="n">lin1</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">weights2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span><span class="mi">32</span><span class="p">)</span>
<span class="n">lin2</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">lin1</span><span class="p">,</span> <span class="n">weights2</span><span class="p">)</span>
<span class="n">lin2</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">lin2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;lin2:&quot;</span><span class="p">,</span><span class="n">lin2</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>lin1: torch.Size([32])
lin2: torch.Size([32])
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally we need to get down to 3 values in the last layer. The position $x$,$y$ and radius $r$. Use a final linear layer to do this transformation:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">weights3</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">32</span><span class="p">)</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">lin2</span><span class="p">,</span><span class="n">weights3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;output:&quot;</span><span class="p">,</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>output: torch.Size([3])
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So we've run through the architecture and checked the dimensions. Now we can use these lines in definition the NN.</p>
<p>I make one modification from the archtiecture described by <a href="https://www.osapublishing.org/optica/abstract.cfm?uri=optica-6-4-506">Helgadottir, Argun, and Volpe (2019)</a>. The final layer only has two outputs $x,y$ rather than $(x,y,r)$. I understand that $r$ became important in training the NN for multi-particle tracking, so will tackle this later.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Flatten" class="doc_header"><code>class</code> <code>Flatten</code><a href="https://github.com/wooduk/deeptracktorch/tree/master/deeptracktorch/models.py#L18" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Flatten</code>() :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">deeptracknet</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">51</span><span class="p">,</span> <span class="mi">51</span><span class="p">))</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([1, 2])</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">nbdev.export</span> <span class="kn">import</span> <span class="n">notebook2script</span>
<span class="n">notebook2script</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Converted 00_simg.ipynb.
Converted 01_model.ipynb.
Converted 02_Train.ipynb.
</pre>
</div>
</div>

</div>
</div>

</div>
    {% endraw %}
</div>
 

