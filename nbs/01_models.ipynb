{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# export \n",
    "import torch\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definitions\n",
    "> The Neural Network models defined in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook defines the NN architectures used in the experiments:\n",
    "1. The Original DeepTrack Network\n",
    "2. A Resnet based network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is needed to replicate the Keras/Tensorflow flatten layer which doesn't seem to have precise equivalent in  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch import nn\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size()[0], -1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original DeepTrack Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Helgadottir, Argun, and Volpe (2019)](https://www.osapublishing.org/optica/abstract.cfm?uri=optica-6-4-506) described the convolutional neural network architecture that they created and trained. The diagram summarising the structure of this network from their paper is shown here:\n",
    "\n",
    "![Architecture Diagram](images/DeepTrackArch.png)\n",
    "\n",
    "In summary this network takes an image 51 x 51 pixels as input and passes it through 3 convolutional layers. Effectively these redescribe the images as features. There are then two densly connected layers which finally connect to a 3 value output layers.\n",
    "\n",
    "   * The first convolutional layer runs 16 3 x 3 kernels over the image, producing 16 channels of size 49 x 49.\n",
    "   * Each of these channels is like a map of intensity for a different feature, perhaps a top edge for example. During training the network learns the weights for these kernels. In effect it learns what features are important for it to minimise error in the output.\n",
    "   * In between the red layers are max-pooling layers that downsample the channels.\n",
    "   * it is typical for the list of features (i.e. number of channels) to rise as we go deeper. This is like detecting richer more complex features as we go along)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation\n",
    "\n",
    "The original paper implements this network using the Keras a Deep Learning framework, based on TensorFlow. Here it is reimplemented using PyTorch to take advantage of the fastai library for efficient training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "DeepTrackNet=nn.Sequential(\n",
    "        # 3 layer convolutions\n",
    "        nn.Conv2d(1,16,3),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.Conv2d(16,32,3),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.Conv2d(32,64,3),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),\n",
    "        \n",
    "        # an additonal undocumented convolutions 128 filters!    \n",
    "        nn.Conv2d(64,128,3),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),\n",
    "        \n",
    "        # dense top\n",
    "        Flatten(),\n",
    "        nn.Linear(128,32),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(32,32),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(32,3)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepTrackNetResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An evolution of the original network design. Add residual layers and make deeper?? [TODO]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_GenerateSyntheticImages.ipynb.\n",
      "Converted 01_Models.ipynb.\n",
      "Converted 02_video.ipynb.\n",
      "Converted 03_measures.ipynb.\n",
      "Converted 98_Display.ipynb.\n",
      "Converted 99_cli.ipynb.\n",
      "Converted E1_Track1.ipynb.\n",
      "Converted E2_Track1fromN.ipynb.\n",
      "Converted E3_multipleparticles.ipynb.\n",
      "Converted Untitled.ipynb.\n",
      "Converted Untitled1.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted tutorial_CNN.ipynb.\n"
     ]
    }
   ],
   "source": [
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
